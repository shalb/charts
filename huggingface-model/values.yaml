## Huggingface model
## @section Model
## ref: https://huggingface.co/models
## @param model.organization Models' company name on huggingface, required!
## @param model.name Models' name on huggingface, required!
## e.g. to deploy model https://huggingface.co/HuggingFaceH4/zephyr-7b-beta use configuration below:
## organization: HuggingFaceH4
## name: zephyr-7b-beta
##
model:
  organization: ""
  name: ""

chat:
  enabled: false
  replicaCount: 1
  podAnnotations: {}
  imagePullSecrets: []
  ## @param chat.affinity Affinity for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: podAffinityPreset, podAntiAffinityPreset, and nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}
  ## @param chat.nodeSelector Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  ## @param chat.tolerations Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  modelConfig: {}
    ## e.g
    # parameters:
    #   temperature: 0.1
    #   top_p: 0.95
    #   repetition_penalty: 1.2
    #   top_k: 50
    #   truncate: 1000
    #   max_new_tokens: 1024
    # datasetName: OpenAssistant/oasst1
    # description: A good alternative to ChatGPT
    # websiteUrl: https://open-assistant.io
    # userMessageToken: "<|prompter|>"
    # assistantMessageToken: "<|assistant|>"
    # messageEndToken: "</s>"
    # preprompt: |
    #   Below are a series of dialogues between various people and an AI assistant. The AI tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant is happy to help with almost anything, and will do its best to understand exactly what is needed. It also tries to avoid giving false or misleading information, and it caveats when it isn't entirely sure about the right answer. That said, the assistant is practical and really does its best, and doesn't let caution get too much in the way of being useful.
    #   -----
    # promptExamples:
    # - title: Write an email from bullet list
    #   prompt: "As a restaurant owner, write a professional email to the supplier to
    #     get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
    # - title: Code a snake game
    #   prompt: Code a basic snake game in python, give explanations for each step.
    # - title: Assist in a task
    #   prompt: How do I make a delicious lemon cheesecake?
    # parameters:
    #   temperature: 0.9
    #   top_p: 0.95
    #   repetition_penalty: 1.2
    #   top_k: 50

  additionalModels: []
    # - name: "Llama-2-70b-chat-hf
    #   endpoints:
    #     - url: "http://exampl.com:8080/model/api"
    #       type: "tgi"
    #   parameters:
    #     temperature: 0.1
    #     top_p: 0.95
    #     repetition_penalty: 1.2
    #     top_k: 50
    #     truncate: 1000
    #     max_new_tokens: 1024
    #   datasetName: OpenAssistant/oasst1
  resources:
    requests:
      cpu: "0.5"
      memory: "512M"
  image:
    repo: "shalb/hf-chat-ui"
    tag: "v0.8"
    pullPolicy: IfNotPresent
  mongodb:
    host: ""
    user: "root"
    password: ""
    port: "27017"
    urlParams: "admin?directConnection=true&authSource=admin"
  ingress:
    enabled: false
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-http"
    hosts:
      - host: api.model.example.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
          - api.model.example.com
        secretName: huggingface-model

## Init configuration. By default, init clone model from Huggingface git using git-lfs.
## The another way is to upload model to s3 bucket to reduce init delay and external traffic.
## @param init.s3.enabled Turn on/off s3 data source Default: disabled
## @param init.s3.bucketURL Full s3 URL included path to model's folder
##
init:
  s3:
    enabled: false
    bucketURL: s3://k8s-model-zephyr/llm/deployment/HuggingFaceH4/zephyr-7b-beta

## Huggingface block configure running text-generation-launcher internal port and additional arguments
## @param huggingface.containerPort Deployment/StatefulSet ContainerPort, optional
##
huggingface:
  containerPort: 8080
  ## @param huggingface.args Additional arg for text-generation-launcher optional
  ## e.g.
  ##  args:
  ##   - "--quantize"
  ##   - "bitsandbytes"
  ##   - "--num-shard"
  ##   - "1"
  ##
  args: []

## @section Global
## @param replicaCount Deployment/StatefulSet replicaCount
##
replicaCount: 1

## @param kind Resource king [allowed values: Deployment/StatefulSet, optional]
##
kind: Deployment

## Huggingface image
## @param image.repo Huggingface image repo
## @param image.tag Huggingface image version
## @param image.pullPolicy Huggingface image pull policy
## ref: https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy
##
image:
  repo: ghcr.io/huggingface/text-generation-inference
  tag: "latest"
  pullPolicy: IfNotPresent

## @param imagePullSecrets May need if used private repo as a cache for image ghcr.io/huggingface/text-generation-inference
#
imagePullSecrets: []

## @param nameOverride String to partially override common.names.name
##
nameOverride: ""

## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""

## Start model pod(s) without limitations on shm memory.
## By default docker and containerd (and possibly other container runtimes) limit `/dev/shm` to `64M`
## ref: https://github.com/containerd/containerd/issues/3654
##
shmVolume:
  ## @param shmVolume.enabled Enable emptyDir volume for /dev/shm for model pod(s)
  ##
  enabled: true
  ## @param shmVolume.sizeLimit Set this to enable a size limit on the shm tmpfs
  ## Note: the size of the tmpfs counts against container's memory limit
  ##
  sizeLimit: "1Gi"

## Persistence parameters
## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
## @param persistence.accessModes PVC accessModes
## @param persistence.storageClassName Kubernetes storageClass name
## @param persistence.storage Volume size
##
persistence:
  accessModes:
  - ReadWriteOnce
  storageClassName: gp2
  storage: 100Gi

## Persistence parameters
## ref: https://kubernetes.io/docs/concepts/services-networking/
## @param service.port Service port, default 8080
## @param service.type Service type, default ClusterIP
##
service:
  port: 8080
  type: "ClusterIP"

## ServiceAccount parameters
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
## @param serviceAccount.create Enable/disable service account, default enabled
## @param serviceAccount.role Kubernetes role configuration, default nil
##
serviceAccount:
  create: true
  role: {}
#     rules:
#     - apiGroups:
#         - ""
#       resources:
#         - endpoints
#         - pods
#         - nodes
#         - services
#       verbs:
#         - get
#         - list

## @param podAnnotations Annotations for replicas pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
##
podAnnotations: {}

## @param updateStrategy specifies the strategy used to replace old Pods by new ones. Can be set to `RollingUpdate`, `OnDelete` (StatefulSet), `Recreate` (Deployment)
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
updateStrategy: {}
## e.g. (rollingUpdate option available Only for Deployment)
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

## Configure Pods Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param securityContext Set pod's Security Context fsGroup
##
securityContext: {}
#   capabilities:
#     drop:
#     - ALL
#   readOnlyRootFilesystem: true
#   runAsNonRoot: true
#   runAsUser: 1000

## @param extraEnvVars Array with extra environment variables to add to main pod
## e.g:
## extraEnvVars:
##   - name: FOO
##     value: "bar"
##
extraEnvVars: []

## Configure the ingresses resources list that allows you to access the model API
## @param ingresses.enabled Enable/disable ingress(es) for model API, default disabled
##
ingress:
  enabled: true
  ## ingresses list
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ## @param ingresses.configs List of ingresses configs
  ## e.g.
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-http"
  hosts:
    - host: api.model.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - hosts:
        - api.model.example.com
      secretName: huggingface-model


## @param livenessProbe Configure extra options for model liveness probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
##
livenessProbe: {}
#   failureThreshold: 4
#   httpGet:
#     path: /
#   initialDelaySeconds: 1
#   periodSeconds: 5
#   successThreshold: 1
#   timeoutSeconds: 3

## @param readinessProbe Configure extra options for model readiness probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
##
readinessProbe: {}
#   failureThreshold: 3
#   httpGet:
#     path: /
#   initialDelaySeconds: 1
#   periodSeconds: 3
#   successThreshold: 2
#   timeoutSeconds: 2

## @param startupProbe Configure extra options for model startup probe
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
##
startupProbe: {}
#   failureThreshold: 10
#   httpGet:
#     path: /
#   initialDelaySeconds: 15
#   periodSeconds: 5
#   successThreshold: 1
#   timeoutSeconds: 3

## PodDisruptionBudget configuration
pdb:
  ## @param pdb.create Specifies whether a PodDisruptionBudget should be created
  ##
  create: false
  ## @param pdb.minAvailable Min number of pods that must still be available after the eviction
  ##
  minAvailable: 1
  ## @param pdb.maxUnavailable Max number of pods that can be unavailable after the eviction
  ##
  maxUnavailable: ""

## Init container's resource requests and limits
## ref: https://kubernetes.io/docs/user-guide/compute-resources/
## @param resources.limits.nvidia.com/gpu The required option by text-generation-launcher
## @param resources.requests.cpu The requested CPU minimal recommended value
## @param resources.requests.memory The requested memory minimal recommended size
##
resources:
  requests:
    cpu: "3"
    memory: "10Gi"
  limits:
    nvidia.com/gpu: 1

## @param extraVolumes Optionally specify extra list of additional volumes for models' pods
## e.g.
##   - hostPath:
##       path: /opt/model/logs
##       type: DirectoryOrCreate
##     name: logging
##
extraVolumes: []

## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for models' container
## e.g.
##   - mountPath: /opt/model/logs
##     name: logging
##
extraVolumeMounts: []

## Model Autoscaling configuration
## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
## @param autoscaling.enabled Enable Horizontal POD autoscaling for model
## @param autoscaling.minReplicas Minimum number of model replicas
## @param autoscaling.maxReplicas Maximum number of model replicas
## @param autoscaling.targetCPU Target CPU utilization percentage
## @param autoscaling.targetMemory Target Memory utilization percentage
##
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPU: 50
  targetMemory: 50

## @param affinity Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
## NOTE: podAffinityPreset, podAntiAffinityPreset, and nodeAffinityPreset will be ignored when it's set
##
affinity: {}
## @param nodeSelector Node labels for pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}
## @param tolerations Tolerations for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []

mongodb:
  install: true
  auth:
    rootPassword: ""
